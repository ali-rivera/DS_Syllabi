---
title: "Intro_DS_TextMining"
author: "Ali Rivera"
date: "2023-08-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidytext)
library(wordcloud)
```

First, we read in all .txt files (you can do this individually with `as.tibble(read_lines("file_name.txt)`) in the current working directory.
**Note: This means the file must be saved in the same folder as the .txt files.**
```{r}
## Get list of all file names in folder
files = list.files()

## Make a large list with text from each files (n=number of files)
all_data <- list()
all_data <- lapply(files, readr::read_lines)

## Rename index (?) with file names -.txt
names(all_data) <- gsub("\\.txt$", "", files)

## List of school names to use later
schools <- names(all_data)
schools <-  Filter(function(x) !any(grep("TextMiningExploration", x)), schools)
```

Then we make a data frame for each syllabus, and for each data frame use `unnest_tokens(word, value)` to separate each word, and `anti_join(stop_words)` to remove the stop words (common words like: it, the, to, etc.), and `filter(is.na(as.numeric(word)))` to remove numeric tokens.
```{r, warning=FALSE, error=FALSE, message=FALSE}
ASU_df <- data_frame(as.tibble(all_data$ASU))
ASU_df <- ASU_df %>% 
  unnest_tokens(word, value) %>% 
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Boston_Uni_df <- data_frame(as.tibble(all_data$Boston_Uni))
Boston_Uni_df <- Boston_Uni_df %>% 
  unnest_tokens(word, value) %>% 
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Brown_df <- data_frame(as.tibble(all_data$Brown))
Brown_df <- Brown_df %>% 
  unnest_tokens(word, value) %>% 
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Cornell_df <- data_frame(as.tibble(all_data$Cornell))
Cornell_df <- Cornell_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

CUNY_df <- data_frame(as.tibble(all_data$CUNY))
CUNY_df <- CUNY_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Drexel_df <- data_frame(as.tibble(all_data$Drexel))
Drexel_df <- Drexel_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Georgia_Tech_df <- data_frame(as.tibble(all_data$Georgia_Tech))
Georgia_Tech_df <- Georgia_Tech_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Harvard_df <- data_frame(as.tibble(all_data$Harvard))
Harvard_df <- Harvard_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

LSU_df <- data_frame(as.tibble(all_data$LSU))
LSU_df <- LSU_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

MIT_df <- data_frame(as.tibble(all_data$MIT))
MIT_df <- MIT_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Montgomery_Coll_df <- data_frame(as.tibble(all_data$Montgomery_Coll))
Montgomery_Coll_df <- Montgomery_Coll_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

NYU_DS4E_df <- data_frame(as.tibble(all_data$NYU_DS4E))
NYU_DS4E_df <- NYU_DS4E_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

NYU_IntroDS_df <- data_frame(as.tibble(all_data$NYU_IntroDS))
NYU_IntroDS_df <- NYU_IntroDS_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Princeton_df <- data_frame(as.tibble(all_data$Princeton))
Princeton_df <- Princeton_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Rutgers_df <- data_frame(as.tibble(all_data$Rutgers))
Rutgers_df <- Rutgers_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UCBerkeley_df <- data_frame(as.tibble(all_data$UCBerkeley))
UCBerkeley_df <- UCBerkeley_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UCSanDiego_df <- data_frame(as.tibble(all_data$UCSanDiego))
UCSanDiego_df <- UCSanDiego_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UIU_107_df <- data_frame(as.tibble(all_data$UIU_107))
UIU_107_df <- UIU_107_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UIU_207_df <- data_frame(as.tibble(all_data$UIU_207))
UIU_207_df <- UIU_207_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UKentucky_df <- data_frame(as.tibble(all_data$UKentucky))
UKentucky_df <- UKentucky_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UMaine_df <- data_frame(as.tibble(all_data$UMaine))
UMaine_df <- UMaine_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UMD_df <- data_frame(as.tibble(all_data$UMD))
UMD_df <- UMD_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UniSys_Georgia_df <- data_frame(as.tibble(all_data$UniSys_Georgia))
UniSys_Georgia_df <- UniSys_Georgia_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

USouthampton_df <- data_frame(as.tibble(all_data$USouthampton))
USouthampton_df <- USouthampton_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UToronto_df <- data_frame(as.tibble(all_data$UToronto))
UToronto_df <- UToronto_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UUtah_df <- data_frame(as.tibble(all_data$UUtah))
UUtah_df <- UUtah_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UVA_SDS_df <- data_frame(as.tibble(all_data$UVA_SDS))
UVA_SDS_df <- UVA_SDS_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UVA_Stat_df <- data_frame(as.tibble(all_data$UVA_Stat))
UVA_Stat_df <- UVA_Stat_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UWashington_df <- data_frame(as.tibble(all_data$UWashington))
UWashington_df <- UWashington_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UWisc_Madison_Modeling_df <- data_frame(as.tibble(all_data$UWisc_Madison_Modeling))
UWisc_Madison_Modeling_df <- UWisc_Madison_Modeling_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UWisc_Madison_Programming_df <- data_frame(as.tibble(all_data$UWisc_Madison_Programming))
UWisc_Madison_Programming_df <- UWisc_Madison_Programming_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UWisconsin_df <- data_frame(as.tibble(all_data$UWisconsin))
UWisconsin_df <- UWisconsin_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

UZurich_df <- data_frame(as.tibble(all_data$UZurich))
UZurich_df <- UZurich_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

Washington_state_df <- data_frame(as.tibble(all_data$Washington_State))
Washington_state_df <- Washington_state_df %>% 
  unnest_tokens(word, value) %>% 
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))

William_and_Mary_df <- data_frame(as.tibble(all_data$William_and_Mary))
William_and_Mary_df <- William_and_Mary_df %>% 
  unnest_tokens(word, value) %>%    
  anti_join(stop_words) %>%    
  filter(is.na(as.numeric(word)))
```

Next, we compile these data frames into a list for easy batch processing.
```{r}
## NTOE: Run once (sequentially) to avoid error 
df_list = mget(ls(pattern = "_df"))
```

For each data frame, we now get a word count and pull the top k (mutable) words in each syllabus. We put these into a data frame `top_10_df` and rename the columns/rows.
```{r}
top_k_df <- data.frame()
k = 20
for (i in seq_along(df_list)) {
  temp <- df_list[[i]] %>% 
    count(word, sort = TRUE) %>% 
    head(k)
  
  top_k_df = rbind(top_k_df, temp$word)
}

colnames(top_k_df) <- seq(1, k, 1)
row.names(top_k_df) <- schools
top_k_df
```

Next, we create a horizontal bar chart for each with the top k words in each syllabus.
```{r}

for (i in seq_along(df_list)) {
  print(df_list[[i]] %>%
    count(word, sort = TRUE) %>%
    head(k) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle(schools[i]))
}
```
We can also create word clouds for the top k words from each syllabus.
```{r}
for (i in seq_along(df_list)) {
  print(schools[i])
  df_list[[i]] %>%
  count(word) %>%
  with(wordcloud(word, n, min.freq=4, max.words = 10))
}
```


